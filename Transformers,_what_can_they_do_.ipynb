{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYV2VxbFWQd3"
   },
   "source": [
    "# Transformers, what can they do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m31oJ7FSWQd4"
   },
   "source": [
    "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pr9QU-fiWQd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: datasets in ./.env/lib/python3.9/site-packages (2.12.0)\n",
      "Requirement already satisfied: evaluate in ./.env/lib/python3.9/site-packages (0.4.0)\n",
      "Requirement already satisfied: torch in ./.env/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in ./.env/lib/python3.9/site-packages (0.15.2)\n",
      "Requirement already satisfied: torchaudio in ./.env/lib/python3.9/site-packages (2.0.2)\n",
      "Requirement already satisfied: transformers[sentencepiece] in ./.env/lib/python3.9/site-packages (4.29.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.env/lib/python3.9/site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in ./.env/lib/python3.9/site-packages (from datasets) (12.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in ./.env/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in ./.env/lib/python3.9/site-packages (from datasets) (2.0.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.env/lib/python3.9/site-packages (from datasets) (2.30.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./.env/lib/python3.9/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in ./.env/lib/python3.9/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in ./.env/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in ./.env/lib/python3.9/site-packages (from datasets) (2023.5.0)\n",
      "Requirement already satisfied: aiohttp in ./.env/lib/python3.9/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in ./.env/lib/python3.9/site-packages (from datasets) (0.14.1)\n",
      "Requirement already satisfied: packaging in ./.env/lib/python3.9/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: responses<0.19 in ./.env/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.env/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: filelock in ./.env/lib/python3.9/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in ./.env/lib/python3.9/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in ./.env/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in ./.env/lib/python3.9/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./.env/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.env/lib/python3.9/site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.env/lib/python3.9/site-packages (from transformers[sentencepiece]) (2023.5.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./.env/lib/python3.9/site-packages (from transformers[sentencepiece]) (0.13.3)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in ./.env/lib/python3.9/site-packages (from transformers[sentencepiece]) (0.1.99)\n",
      "Requirement already satisfied: protobuf<=3.20.2 in ./.env/lib/python3.9/site-packages (from transformers[sentencepiece]) (3.20.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.env/lib/python3.9/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./.env/lib/python3.9/site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.env/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./.env/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.env/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.env/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.env/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.env/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.env/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.env/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.env/lib/python3.9/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.env/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.env/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.env/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.env/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.env/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install datasets evaluate torch torchvision torchaudio \"transformers[sentencepiece]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mQ6kHszaWQd5",
    "outputId": "1fe3fcc7-b489-4665-e182-4c47fe1fa19d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598050713539124}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XihZnF_hWQd5",
    "outputId": "30a6d076-1c47-4720-dfbe-f4a2d48f5df7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598050713539124},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    [\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6wkW--SYWQd6",
    "outputId": "1e3002ee-d433-40e0-b8bb-082741b1c197"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading (…)lve/main/config.json: 100%|██| 1.15k/1.15k [00:00<00:00, 283kB/s]\n",
      "Downloading pytorch_model.bin: 100%|███████| 1.63G/1.63G [01:42<00:00, 15.8MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|███| 26.0/26.0 [00:00<00:00, 16.8kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|███| 899k/899k [00:00<00:00, 22.7MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|███| 456k/456k [00:00<00:00, 30.8MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|█| 1.36M/1.36M [00:00<00:00, 5.86MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformers library',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.8445950150489807, 0.11197729408740997, 0.0434277318418026]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Sg4MwiKRWQd6",
    "outputId": "b82d1b5a-1552-46d1-af8d-c2b3d2b31812"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading (…)lve/main/config.json: 100%|██████| 665/665 [00:00<00:00, 230kB/s]\n",
      "Downloading pytorch_model.bin: 100%|█████████| 548M/548M [00:30<00:00, 18.1MB/s]\n",
      "Downloading (…)neration_config.json: 100%|██████| 124/124 [00:00<00:00, 113kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|█| 1.04M/1.04M [00:00<00:00, 4.88MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|███| 456k/456k [00:00<00:00, 7.43MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|█| 1.36M/1.36M [00:00<00:00, 9.62MB/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/Users/marc/Desktop/HF/huggingface-course/.env/lib/python3.9/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (50) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to run an agile web app from start to finish. With our new 3D Studio feature, our team gets to apply 3D Studio to the next level of web development in terms of building content for web'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\")\n",
    "generator(\"In this course, we will teach you how to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1m3vS9BMWQd6",
    "outputId": "dc772c3e-6eba-4ae5-bcbd-381c0c9582f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████| 762/762 [00:00<00:00, 205kB/s]\n",
      "Downloading pytorch_model.bin: 100%|█████████| 353M/353M [00:16<00:00, 21.6MB/s]\n",
      "Downloading (…)neration_config.json: 100%|██████| 124/124 [00:00<00:00, 126kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|█| 1.04M/1.04M [00:00<00:00, 14.3MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|███| 456k/456k [00:00<00:00, 19.1MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|█| 1.36M/1.36M [00:00<00:00, 15.5MB/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to master this skill without going through any other lessons or exams. You will learn how to get rid of'},\n",
       " {'generated_text': 'In this course, we will teach you how to generate a basic Java class using JAX/JAX. From this course, we will use J'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "generator(\n",
    "    \"In this course, we will teach you how to\",\n",
    "    max_length=30,\n",
    "    num_return_sequences=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "L3KeYCzJWQd6",
    "outputId": "12088daa-d665-4c00-cae9-d440bb64d4ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading (…)lve/main/config.json: 100%|██████| 480/480 [00:00<00:00, 478kB/s]\n",
      "Downloading pytorch_model.bin: 100%|█████████| 331M/331M [00:18<00:00, 18.4MB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|███| 899k/899k [00:00<00:00, 18.6MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|███| 456k/456k [00:00<00:00, 21.2MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|█| 1.36M/1.36M [00:00<00:00, 21.1MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.1961977630853653,\n",
       "  'token': 30412,\n",
       "  'token_str': ' mathematical',\n",
       "  'sequence': 'This course will teach you all about mathematical models.'},\n",
       " {'score': 0.04052729532122612,\n",
       "  'token': 38163,\n",
       "  'token_str': ' computational',\n",
       "  'sequence': 'This course will teach you all about computational models.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline(\"fill-mask\")\n",
    "unmasker(\"This course will teach you all about <mask> models.\", top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "uE5r87H1WQd6",
    "outputId": "b56f9661-53a3-446a-a73f-20d74946632e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading (…)lve/main/config.json: 100%|█████| 998/998 [00:00<00:00, 1.35MB/s]\n",
      "Downloading pytorch_model.bin: 100%|███████| 1.33G/1.33G [01:07<00:00, 19.8MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|███| 60.0/60.0 [00:00<00:00, 35.0kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|███| 213k/213k [00:00<00:00, 28.7MB/s]\n",
      "/Users/marc/Desktop/HF/huggingface-course/.env/lib/python3.9/site-packages/transformers/pipelines/token_classification.py:169: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9981694,\n",
       "  'word': 'Sylvain',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9796021,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 33,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9932106,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MWXFqRpvWQd7",
    "outputId": "0a6aa4da-7995-47a1-8570-ecc5caed08ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading (…)lve/main/config.json: 100%|██████| 473/473 [00:00<00:00, 610kB/s]\n",
      "Downloading pytorch_model.bin: 100%|█████████| 261M/261M [00:13<00:00, 19.6MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|███| 29.0/29.0 [00:00<00:00, 37.5kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|███| 213k/213k [00:00<00:00, 31.2MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|███| 436k/436k [00:00<00:00, 22.4MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.6949763894081116, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\")\n",
    "question_answerer(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "yOLnuHR2WQd7",
    "outputId": "c08edba6-9065-4aa3-88a6-bd8cf47baf80"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading (…)lve/main/config.json: 100%|█| 1.80k/1.80k [00:00<00:00, 2.15MB/s]\n",
      "Downloading pytorch_model.bin: 100%|███████| 1.22G/1.22G [01:16<00:00, 15.9MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|███| 26.0/26.0 [00:00<00:00, 11.8kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|███| 899k/899k [00:00<00:00, 23.5MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|███| 456k/456k [00:00<00:00, 26.3MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil,    electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India continue to encourage and advance the teaching of engineering .'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer(\n",
    "    \"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of \n",
    "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
    "    the premier American universities engineering curricula now concentrate on \n",
    "    and encourage largely the study of engineering science. As a result, there \n",
    "    are declining offerings in engineering subjects dealing with infrastructure, \n",
    "    the environment, and related issues, and greater concentration on high \n",
    "    technology subjects, largely supporting increasingly complex scientific \n",
    "    developments. While the latter is important, it should not be at the expense \n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other \n",
    "    industrial countries in Europe and Asia, continue to encourage and advance \n",
    "    the teaching of engineering. Both China and India, respectively, graduate \n",
    "    six and eight times as many traditional engineers as does the United States. \n",
    "    Other industrial countries at minimum maintain their output, while America \n",
    "    suffers an increasingly serious decline in the number of engineering graduates \n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "m0B7TvN6WQd7",
    "outputId": "f1f288eb-ca21-42a0-df77-5c33293d4c6d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|█| 1.42k/1.42k [00:00<00:00, 1.94MB/s]\n",
      "Downloading pytorch_model.bin: 100%|█████████| 301M/301M [00:20<00:00, 14.4MB/s]\n",
      "Downloading (…)neration_config.json: 100%|██████| 293/293 [00:00<00:00, 275kB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|███| 42.0/42.0 [00:00<00:00, 49.1kB/s]\n",
      "Downloading (…)olve/main/source.spm: 100%|███| 802k/802k [00:00<00:00, 29.2MB/s]\n",
      "Downloading (…)olve/main/target.spm: 100%|███| 778k/778k [00:00<00:00, 21.7MB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|█| 1.34M/1.34M [00:00<00:00, 21.1MB/s]\n",
      "/Users/marc/Desktop/HF/huggingface-course/.env/lib/python3.9/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'This course is produced by Hugging Face.'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "translator(\"Ce cours est produit par Hugging Face.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Transformers, what can they do?",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
